[{"path":"index.html","id":"preface","chapter":"1 Preface","heading":"1 Preface","text":"created notes working Regression Stories, Andrew Gelman, Jennifer Hill, Aki Vehtari. chapter summarizes main points, provide additional explanations topics found difficult. Although authors wrote code base R style, written code examples using Tidyverse packages.delighted people find notes useful. Corrections suggestions via pull request welcome!","code":""},{"path":"overview.html","id":"overview","chapter":"2 Overview","heading":"2 Overview","text":"example regression. Positive economic growth election strong predictor incumbent vote percentage.Now fit Bayesian model show 200 lines drawn posterior distribution visualize uncertainty.","code":"\nlibrary(tidyverse)\nlibrary(extrafont)\nlibrary(rstanarm)\n\nlibrary(modelr)\nlibrary(tidybayes)\nlibrary(gganimate)\n# Figure 1.1\n\ndf <- read.table(\"~/ROS_notes/ROS-Examples-master/ElectionsEconomy/data/hibbs.dat\", header=TRUE)\n\n# Convert from percentage to decimal\ndf$growth <- df$growth / 100\ndf$vote <- df$vote / 100\n\ndf %>%\n  ggplot(aes(x = growth, y = vote, label = year)) +\n  geom_point(shape=21, stroke=0.5, fill=\"steelblue\", size=2) +\n  geom_text(nudge_y = -0.015, size=3.5) +\n  stat_smooth(geom='line', alpha=0.5, se=TRUE, method='lm', color=\"steelblue\") +\n  stat_smooth(geom='ribbon', method='lm', alpha=0.2, fill=\"gray\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.30, 0.70)) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  cowplot::theme_cowplot() +\n  theme(text=element_text(size=12, family=\"Source Sans Pro\"))+\n  labs(\n    title = \"Economic growth predicts incumbent vote percentage\",\n    x = \"Average recent growth in personal income\",\n    y = \"Incumbent vote percentage\",\n    caption = \"Data ranges from 1952 to 2012\"\n  )\nfit <- stan_glm(vote ~ growth, data=df, refresh = 0)\n\nfit## stan_glm\n##  family:       gaussian [identity]\n##  formula:      vote ~ growth\n##  observations: 16\n##  predictors:   2\n## ------\n##             Median MAD_SD\n## (Intercept) 0.5    0.0   \n## growth      3.0    0.7   \n## \n## Auxiliary parameter(s):\n##       Median MAD_SD\n## sigma 0.0    0.0   \n## \n## ------\n## * For help interpreting the printed output see ?print.stanreg\n## * For info on the priors used see ?prior_summary.stanreg\ndf %>%\n  data_grid(growth = seq_range(growth, n = 150)) %>%\n  add_fitted_draws(fit, n = 200) %>%\n  ggplot(aes(x = growth, y = vote)) +\n  geom_line(aes(y = .value, group = .draw), alpha = .1) +\n  geom_point(data = df, shape=21, stroke=0.5, fill=\"steelblue\", size=2) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.30, 0.70)) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  cowplot::theme_cowplot() +\n  theme(text = element_text(size = 12, family = \"Source Sans Pro\")) +\n  labs(\n    title = \"Economic growth predicts incumbent vote percentage\",\n    x = \"Average recent growth in personal income\",\n    y = \"Incumbent vote percentage\",\n    caption = \"Data ranges from 1952 to 2012\"\n  )\np <- ggplot(iris, aes(x = Petal.Width, y = Petal.Length)) +\n  geom_point() +\n  transition_states(Species,\n                    transition_length = 2,\n                    state_length = 1)\n\nanimate(p, renderer = ffmpeg_renderer(), fps=60, height=1000, width=1000, res=300, nframes=300)"},{"path":"data-and-measurement.html","id":"data-and-measurement","chapter":"3 Data and Measurement","heading":"3 Data and Measurement","text":"","code":"\nlibrary(tidyverse)"},{"path":"basic-probability-and-statistics.html","id":"basic-probability-and-statistics","chapter":"4 Basic Probability and Statistics","heading":"4 Basic Probability and Statistics","text":"code generate plot 1000 samples bivariate normal distribution.\nFigure 4.1: 1,000 samples bivariate normal distribution mean vector (3,5), standard deviation vector (2,1), rho = 0.7.\n","code":"\nlibrary(tidyverse)\nlibrary(extrafont)\n\nlibrary(MASS)\n# Set parameters\nset.seed(7)\n\nmean1 <- 3\nmean2 <- 5\n\nsd1 <- 2\nsd2 <- 1\nrho <- 0.7\n\n# Compute the covariance from the variances and the correlation\ncov <- rho * sd1 * sd2\n\n# Generate 1000 draws\nm <- mvrnorm(n = 1000, mu = c(mean1, mean2), Sigma = matrix(c(sd1^2, cov, cov, sd2^2), nrow=2))\n\n# Set column names and convert to tibble\ncolnames(m) <- c(\"x1\", \"x2\")\ndf <- as_tibble(m)\ndf %>%\n  ggplot(aes(x=x1, y=x2)) +\n  geom_point(alpha=0.4, fill=\"#005394\", shape=21) +\n  scale_x_continuous(limits=c(-5,12)) +\n  scale_y_continuous(limits=c(0,10)) +\n  cowplot::theme_minimal_grid() +\n  labs(x = \"X_1\",\n       y = \"X_2\") +\n  theme(text = element_text(size = 12, family = \"Source Sans Pro\"))\n# Test the equation for sd(X1+X2)\n\nsd(m[,1] + m[,2])## [1] 2.755895\nsqrt(sd1^2 + sd2^2 + 2*cov)## [1] 2.792848"},{"path":"statistical-inference.html","id":"statistical-inference","chapter":"5 Statistical Inference","heading":"5 Statistical Inference","text":"","code":"\nlibrary(tidyverse)"},{"path":"bias-and-variance.html","id":"bias-and-variance","chapter":"6 Bias and Variance","heading":"6 Bias and Variance","text":"","code":"\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(extrafont)"},{"path":"bias-and-variance.html","id":"overview-1","chapter":"6 Bias and Variance","heading":"6.1 Overview","text":"chapter examine frequentist properties classical linear regression procedure. Specifically, examine bias, variance, mean squared error parameters estimated procedure.Recall assumptions classical linear regression. assume true linear relationship \\(y = ax + b + \\epsilon\\) outcome variable, \\(y\\), predictor variable, \\(x\\). slope linear relationship \\(m\\), y-intercept \\(b\\). error term, \\(\\epsilon\\), assumed normally distributed mean, \\(\\mu\\), equal zero, standard deviation \\(\\sigma\\). value \\(\\sigma\\) determines amount variability data point around true linear relationship.fit classical linear regression model, estimating three unknown parameters:slope true linear relationship, \\(\\)y-intercept true linear relationship, \\(b\\)standard deviation error term, \\(\\sigma\\)Remember regression models generative models. can generate random samples data . generate data model? Let’s assume concreteness predicting height (\\(y\\)) weight (\\(x\\)). someone weight \\(x_1\\), predict height, given know true model parameters? height normally distributed mean \\(ax_1 + b\\) standard deviation \\(\\sigma\\), assume know values \\(\\), \\(b\\), \\(\\sigma\\). crucial realize even know true model, make predictions certainty! always limited irreducible error present error term, \\(\\epsilon\\).now instead knowing model’s true parameters, estimate data. collect infinite amount data uncertainty \\(\\), \\(b\\), \\(\\sigma\\) go zero. never able make exact predictions new data points still bounded error \\(\\epsilon\\). fit classical regression model data, obtain uncertain parameter estimates model , construction, makes uncertain predictions.crucial understand two separate sources uncertainty – uncertainty model parameters due fitting model data subject random noise, uncertainty value new predictions due error term model. make prediction model, must take sources uncertainty account.","code":""},{"path":"bias-and-variance.html","id":"simulating-from-the-model","chapter":"6 Bias and Variance","heading":"6.2 Simulating from the model","text":"Let’s start turning ideas R code. start assuming known model show generate random datasets . ’s example model.\n\\[\n\\begin{align*}\ny &= 5x + 3 + \\epsilon \\\\\n\\epsilon &\\sim \\operatorname{Normal}(0, 6)\n\\end{align*}\n\\]\nwords, true relationship \\(x\\) \\(y\\) described line \\(y = 5x+3\\). Given data point \\(x_1\\) can generate corresponding value \\(y_1\\) adding random noise sampled \\(\\operatorname{Normal}(0, 6)\\) deterministic prediction \\(5x_1 + 3\\). equivalent sampling directly distribution \\(\\operatorname{Normal}(5x_1 + 3, 6)\\).Now let’s actually carry procedure. First let’s generate bunch sample \\(x\\) values. can use range 1 10 steps 0.25 simplicity.model can generate \\(y\\) value corresponding \\(x\\) value. Remember random process! get results every time. First, model without random component. expected, obtain perfect line.\nNow let’s add random component. every \\(y\\) value, add random value sampled \\(\\operatorname{Normal}(0, 0.5)\\).Try running code time, see generate new dataset time. mean say classical linear regression model generative model. ’s animation sampling datasets.","code":"\nx <- seq(1, 10, by=0.25)\ny <- (5*x) + 3\n\nqplot(x,y)\ny <- (5*x) + 3\n\n# Recall that `rnorm` is parameterized by the standard deviation, not the variance\n# so we need to take a square root\ny <- y + rnorm(n = length(y), mean=0, sd=sqrt(6))\n\nqplot(x,y)\ndf <- crossing(x, dataset=1:5)\n\ndf$dataset <- as.factor(df$dataset)\n\ndf$y <- ((5*df$x) + 3) + rnorm(n = length(df$x), mean=0, sd=sqrt(6))\n\ndf %>%\n  ggplot(aes(x=x, y=y, fill=dataset))+\n  geom_point(shape=21) +\n  geom_abline(intercept = 3, slope = 5, color=\"black\", alpha=0.5)+\n  cowplot::theme_cowplot() +\n  scale_color_brewer(palette=\"Dark2\") +\n  theme(text = element_text(size = 12, family = \"Source Sans Pro\")) +\n  labs(title = \"Five generated datasets from our linear model\") +\n  transition_states(dataset, transition_length = 0.5, state_length = 1) -> anim\n\nanimate(anim, renderer = ffmpeg_renderer(), height=1500, width=2200, res=300)"},{"path":"bias-and-variance.html","id":"fitting-a-model-using-the-lm-function","chapter":"6 Bias and Variance","heading":"6.3 Fitting a model using the lm function","text":"TODO","code":""},{"path":"bias-and-variance.html","id":"bias-variance-and-mean-squared-error-of-estimates","chapter":"6 Bias and Variance","heading":"6.4 Bias, variance, and mean squared error of estimates","text":"Now let’s estimate frequentist properties classical linear regression procedure. function generates \\(n\\) points linear regression model true model parameters \\(\\), \\(b\\), \\(\\sigma\\). start \\(x\\) values evenly spaced 0 10 defaults, can modified.’s example data generated generate_dataset function.happens varythe number data points used fit model?value \\(\\)value \\(b\\)value \\(\\sigma\\)change range \\(x\\) valuesLet experiment simulations find !","code":"\ngenerate_dataset <- function(n = 100, a, b, sigma, min = 0, max = 10) {\n  x <- seq(min, max, length.out = n)\n  y <- (a * x) + b\n  y <- y + rnorm(n = length(y), mean = 0, sd = sigma)\n\n  df <- tibble(x, y)\n\n  return(df)\n}\n\n# These are functions that extract the intercept and slope estimates respectively\n# from a fitted linear model\nget_intercept <- function(fit){\n  return(coef(fit)[1])\n}\n\nget_slope <- function(fit){\n  return(coef(fit)[2])\n}\ngenerated_data <- generate_dataset(a=5, b=3, sigma=sqrt(6))\n\nhead(generated_data)## # A tibble: 6 x 2\n##       x     y\n##   <dbl> <dbl>\n## 1 0      4.12\n## 2 0.101  2.62\n## 3 0.202  5.60\n## 4 0.303  2.55\n## 5 0.404  2.30\n## 6 0.505  9.88\ndfs <- map(1:1e4, ~generate_dataset(a=5, b=3, sigma=sqrt(6))) \n\nslope_estimates <- map_dbl(dfs, ~lm(y~x, data= .x) %>% get_slope())\nintercept_estimates <- map_dbl(dfs, ~lm(y~x, data= .x) %>% get_intercept())\nslope_estimates[1:5]## [1] 5.192761 4.910203 5.056036 5.048160 4.920561\n# Mean of the slope estimates\n# We see that it is unbiased\nmean(slope_estimates)## [1] 5.000322\n# Standard Error of the slope estimates\nsd(slope_estimates)## [1] 0.08443499\nhist(slope_estimates,\n     breaks=50,\n     main=\"Slope estimates are unbiased\",\n     xlab = \"Estimate\")\n\nabline(v = 5, col=\"red\", )\nintercept_estimates[1:5]## [1] 2.106986 3.191357 3.046941 2.632165 3.372357\n# Mean of the intercept estimates\n# We see that it is unbiased\nmean(intercept_estimates)## [1] 2.997504\n# Standard Error of the intercept estimates\nsd(intercept_estimates)## [1] 0.4881937\nhist(intercept_estimates,\n     breaks=50,\n     main=\"Slope estimates are unbiased\",\n     xlab = \"Estimate\")\n\nabline(v = 3, col=\"red\", )"},{"path":"what-is-a-statistic.html","id":"what-is-a-statistic","chapter":"7 What is a Statistic?","heading":"7 What is a Statistic?","text":"","code":"\nlibrary(tidyverse)\nlibrary(extrafont)"},{"path":"what-is-a-statistic.html","id":"simulating-statistics-of-dice-rolls","chapter":"7 What is a Statistic?","heading":"7.1 Simulating statistics of dice rolls","text":"\nFigure 7.1: Various order statistics rolls 5 standard dice. Frequencies calculated using 100,000 simulations.\n","code":"\n# A function to roll `n` dice\nroll <- function(n){\n  sample(x = 1:6, size=n, replace=TRUE)\n}\n\n# Returns the nth order statistic of the sample\norder_stat <- function(x, n){\n  x <- sort(x)\n  return(x[n])\n}\n# Roll 5 dice 100,000 times\ndata <- map(1:1e5, ~roll(5))\n\n# Look at first three rolls\ndata[1:3]## [[1]]\n## [1] 4 2 3 5 4\n## \n## [[2]]\n## [1] 2 6 4 2 3\n## \n## [[3]]\n## [1] 2 5 4 4 1\n# Generate various statistics for each roll\nmedians <- map_dbl(data, ~median(.x))\nmeans <- map_dbl(data, ~mean(.x))\nminimums <- map_dbl(data, ~min(.x))\nmaximums <- map_dbl(data, ~max(.x))\nsecond_order_stat <- map_dbl(data, ~order_stat(x=.x, n=2))\nranges <- maximums - minimums\ndf <- tibble(medians, means, minimums, maximums, second_order_stat, ranges)\n\ndf <- pivot_longer(df, cols = everything())"}]
